{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a4f7453469c0b",
   "metadata": {},
   "source": [
    "# Amazon Books Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1ca7a8cc61d5",
   "metadata": {},
   "source": [
    "This project is about **market-basket analysis** on a dataset of Amazon books reviews. The goal is to find association rules between books, in order to suggest to the users which books they might be interested in, based on the reviews they have already made.\n",
    "\n",
    "The dataset is downloaded from Kaggle via its API and unzipped in two different files:\n",
    "* `Books_rating.csv` contains the reviews of the books.\n",
    "* `Books_data.csv` contains information about books."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:27:55.061991Z",
     "start_time": "2025-03-31T13:27:54.397749Z"
    }
   },
   "source": "! pip install kaggle",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.4.2)\r\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (6.2.0)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2025.1.31)\r\n",
      "Requirement already satisfied: charset-normalizer in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (3.4.1)\r\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (3.10)\r\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (5.29.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-slugify in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (8.0.4)\r\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (75.8.0)\r\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (1.17.0)\r\n",
      "Requirement already satisfied: text-unidecode in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (1.3)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (4.67.1)\r\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2.3.0)\r\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (0.5.1)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e487d33828adccd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:37.841590Z",
     "start_time": "2025-03-31T13:27:55.070026Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"lorispalmarin\"\n",
    "os.environ['KAGGLE_KEY'] = \"093953c742e5b0e7f5ff80eb62b89eba\"\n",
    "!kaggle datasets download --unzip mohamedbakhet/amazon-books-reviews"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\r\n",
      "License(s): CC0-1.0\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2cb61fd0077562aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:40.558639Z",
     "start_time": "2025-03-31T13:28:37.966497Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, lower"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "22730f220c2f3d10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Spark Setup\n",
    "\n",
    "The first step is to create a Spark session to work with the data. We will use the `SparkSession` class to create a new session, and the `SparkContext` class to interact with the Spark cluster. The session will be created with the name \"Books Reviews\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "aafed9bea066dc63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:42.961438Z",
     "start_time": "2025-03-31T13:28:40.565658Z"
    }
   },
   "source": [
    "spark = SparkSession.builder.appName(\"Books Reviews\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/31 15:28:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "9e48ced7aa77962a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Upload and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549ca1e303e130",
   "metadata": {},
   "source": [
    "We uploaded the dataset within the Jupyter environment. Now, we will load the data into a Spark DataFrame and perform some pre-processing operations.\n",
    "\n",
    "### Books Ratings"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad67d628c41d7f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:50.553769Z",
     "start_time": "2025-03-31T13:28:42.969079Z"
    }
   },
   "source": [
    "date = spark.read.csv(\"Books_rating.csv\", header=True, inferSchema=True)\n",
    "date = date.withColumnRenamed(\"review/score\", \"review_score\") # just convenience in SQL\n",
    "date.show(5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review_score|review/time|      review/summary|         review/text|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...| NULL|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
      "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "41b06da891ffc27c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sampling\n",
    "In order to ease operations on the dataset during project design, we introduced a `sampling` variable to keep only a fraction of the users (1%). This will allow us to work with a smaller dataset and speed up the operations.\n",
    "\n",
    "If `sampling` is set to `True`, the dataset will be sampled. Otherwise, the dataset will be kept as it is."
   ]
  },
  {
   "cell_type": "code",
   "id": "36bfc332b2b521de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:50.576465Z",
     "start_time": "2025-03-31T13:28:50.573719Z"
    }
   },
   "source": [
    "sampling = False\n",
    "sample_fraction = 0.01\n",
    "\n",
    "if sampling == True:\n",
    "    user_sample = (date.select(\"User_id\").distinct().sample(fraction=sample_fraction, seed=42))\n",
    "    date = date.join(user_sample, on=\"User_id\", how=\"inner\")\n",
    "else:\n",
    "    date = date"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "8aed99df1061f41e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dealing with Duplicates\n",
    "\n",
    "Next, we take books with same title and different IDs and we keep only one ID for each book.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce359cc92dd1cb48",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, first\n",
    "\n",
    "date = date.withColumn(\"title\", lower(col(\"title\")))\n",
    "\n",
    "df_unique = date.groupBy(\"Title\").agg(first(\"Id\").alias(\"New_Id\"))\n",
    "\n",
    "df_final = date.join(df_unique, on=\"Title\", how=\"left\").drop(\"Id\").withColumnRenamed(\"New_Id\", \"Id\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:32:12.332389Z",
     "start_time": "2025-03-31T13:32:07.972037Z"
    }
   },
   "cell_type": "code",
   "source": "df_final.show(5)",
   "id": "db3afdf01c06b052",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:==========================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|               title|Price|       User_id|         profileName|review/helpfulness|review_score|review/time|      review/summary|         review/text|        Id|\n",
      "+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "|its only art if i...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|1882931173|\n",
      "|moby dick or the ...| NULL|A1G37DFO8MQW0M|\"C. M Mills \"\"Mic...|               3/4|         5.0| 1205193600|Moby Dick is a Wh...|\"Herman Melville ...|B000J6DLBU|\n",
      "|moby dick or the ...| NULL| AJ98YA4Y333BK|       \"CJA \"\"CJA\"\"\"|               3/4|         5.0| 1190073600|Slog Through It -...|This great Americ...|B000J6DLBU|\n",
      "|moby dick or the ...| NULL| AB68LG08VDFL3|             R. Icks|               3/4|         5.0| 1188345600|      Strange but...|The strangeness i...|B000J6DLBU|\n",
      "|moby dick or the ...| NULL|          NULL|                NULL|               3/4|         4.0| 1170806400|Moby Dick Book Re...|Moby Dick, by Her...|B000J6DLBU|\n",
      "+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "e5fbed79188b1e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:59.283400Z",
     "start_time": "2025-03-31T13:28:57.002071Z"
    }
   },
   "source": [
    "print('Dataset has', df_final.count(), 'reviews.')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 3000000 reviews.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "1931e406f2f1977d",
   "metadata": {},
   "source": [
    "I created a SQLContext to work with SQL queries on the DataFrame. I will use it to filter the columns I need, which are `Id` and `User_id`."
   ]
  },
  {
   "cell_type": "code",
   "id": "dd35eb5f8aa6f801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:28:59.338320Z",
     "start_time": "2025-03-31T13:28:59.296432Z"
    }
   },
   "source": [
    "df_final.createOrReplaceTempView(\"ratings\")\n",
    "query = \"SELECT Id, User_id FROM ratings\"\n",
    "data = spark.sql(query)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "51627db6828cd5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:03.700858Z",
     "start_time": "2025-03-31T13:28:59.350182Z"
    }
   },
   "source": [
    "data.show(5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===========================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|        Id|       User_id|\n",
      "+----------+--------------+\n",
      "|1882931173| AVCGYZL8FQQTD|\n",
      "|B000J6DLBU|A1G37DFO8MQW0M|\n",
      "|B000J6DLBU| AJ98YA4Y333BK|\n",
      "|B000J6DLBU| AB68LG08VDFL3|\n",
      "|B000J6DLBU|          NULL|\n",
      "+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "1990ae069453bf5f",
   "metadata": {},
   "source": "The dataset contains **3 milions** of reviews. We now remove duplicates and null values."
  },
  {
   "cell_type": "code",
   "id": "af6c022303c1566f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:03.773908Z",
     "start_time": "2025-03-31T13:29:03.724113Z"
    }
   },
   "source": [
    "data = data.dropDuplicates().cache()\n",
    "data = data.dropna()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "88596d09b203f425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:16.148174Z",
     "start_time": "2025-03-31T13:29:03.792443Z"
    }
   },
   "source": [
    "data.count()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:29:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2046358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "f44028f031cd1944",
   "metadata": {},
   "source": [
    "After removing duplicates and null values, the dataset contains about **2.1 milions** of reviews. I will check the schema of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d9c42ffa4e906b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:16.161081Z",
     "start_time": "2025-03-31T13:29:16.157595Z"
    }
   },
   "source": [
    "data.printSchema()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "8bd378ccad0e9c8",
   "metadata": {},
   "source": [
    "The schema of the DataFrame is correct.\n",
    "\n",
    "We will check the number of different users and books in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d02ee86e35b6dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:18.142214Z",
     "start_time": "2025-03-31T13:29:16.182787Z"
    }
   },
   "source": [
    "print(\"Dataset contains\", data.select(\"User_id\").distinct().count(), \"different users\")\n",
    "print(\"Dataset contains\", data.select(\"Id\").distinct().count(), \"different books\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1008423 different users\n",
      "Dataset contains 203791 different books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "7489a6de236c3540",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "Now, we will implement two different algorithms to find association rules between books. The first one is the **A-Priori **, which is a classical algorithm for market-basket analysis. The second is the **SON algorithm**, which is a more efficient version of the A-Priori, designed to work with large datasets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f105d8e9ce426",
   "metadata": {},
   "source": [
    "### 1. A-Priori Algorithm\n",
    "\n",
    "The A-Priori Algorithm is a two-pass approach designed to efficiently find frequent itemsets while reducing memory usage. Instead of storing all possible item pairs, it eliminates infrequent items early, making the counting process more efficient.\n",
    "\n",
    "At first, we created baskets from original data and stored them in a RDD:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a753afb9fdf00a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:23.314414Z",
     "start_time": "2025-03-31T13:29:18.727839Z"
    }
   },
   "source": [
    "book_baskets = (data.rdd.\n",
    "                map(lambda row: (row[\"User_id\"], row[\"Id\"])).\n",
    "                groupByKey().\n",
    "                mapValues(list))\n",
    "book_baskets.take(5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A2JENYWRQHT8TW', ['0759614512']),\n",
       " ('A3ANBQAF4OY0P1', ['1416509879']),\n",
       " ('AFW72F92KX7AJ', ['B0002ST9TI']),\n",
       " ('ACTMM7G8M2LW3', ['B000NQ655K', 'B0006AWDI6', 'B000OW4E7O']),\n",
       " ('A23KYX0MQS9S4J', ['1588209202'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "bedd10b5a25b7632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:23.889622Z",
     "start_time": "2025-03-31T13:29:23.330535Z"
    }
   },
   "source": [
    "number_of_baskets = book_baskets.count()\n",
    "number_of_baskets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008423"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "777af1b221ca891a",
   "metadata": {},
   "source": [
    "#### First pass: Finding frequent singletons\n",
    "\n",
    "In this step, we will find the singletons that appear more than a certain threshold in the dataset. We will count the occurrences of each book and filter the frequent ones.\n",
    "\n",
    "At first, I counted all singletons:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ec2937aa3ab43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:36:28.880026Z",
     "start_time": "2025-03-31T13:36:27.084738Z"
    }
   },
   "source": [
    "single_counts = (\n",
    "    book_baskets.\n",
    "    flatMap(lambda r:r[1]). # isolates movies\n",
    "    map(lambda r: (r,1)). # count = 1 for each movie\n",
    "    reduceByKey(lambda a, b: a + b). # group and sum movies count\n",
    "    collect() # convert to list\n",
    ")\n",
    "single_counts[0:5]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('B000OW4E7O', 487),\n",
       " ('B00005X55Y', 190),\n",
       " ('B000NKGYNE', 44),\n",
       " ('B000PC55CG', 58),\n",
       " ('0553289713', 1578)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "a18f8f9e8e623c6d",
   "metadata": {},
   "source": "Then, we filtered the frequent singletons comparing them to a support threshold:"
  },
  {
   "cell_type": "code",
   "id": "5e6c825ddf455a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:24.942966Z",
     "start_time": "2025-03-31T13:29:24.927573Z"
    }
   },
   "source": [
    "percentage_of_total = 0.001\n",
    "support_threshold = percentage_of_total * number_of_baskets\n",
    "frequent_singletons = list(filter(lambda r: r[1] >= support_threshold, single_counts))\n",
    "frequent_singletons\n",
    "print(\"There is a total of\", len(frequent_singletons), \"frequent singletons\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 81 frequent singletons\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d6963adf8d222303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:24.955529Z",
     "start_time": "2025-03-31T13:29:24.953377Z"
    }
   },
   "source": [
    "frequent_singletons_list = [x[0] for x in frequent_singletons]"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "270f78554fa19f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:37:06.597973Z",
     "start_time": "2025-03-31T13:37:06.588879Z"
    }
   },
   "source": "frequent_singletons[0:5]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0553289713', 1578),\n",
       " ('B000PMCF1A', 2125),\n",
       " ('B0002XH6T8', 1408),\n",
       " ('B000K0DB8I', 1469),\n",
       " ('B000NWU3I4', 3562)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "55e2d28e4ad53e84",
   "metadata": {},
   "source": [
    "#### Second pass: finding frequent pairs\n",
    "\n",
    "Using map-reduce, we will count the occurrences of pairs of frequent books in the baskets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "365c7639cbefef35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:37:36.745196Z",
     "start_time": "2025-03-31T13:37:35.069459Z"
    }
   },
   "source": [
    "pairs_counts = (\n",
    "      book_baskets\n",
    "      .map(lambda r:r[1])\n",
    "      .map(lambda r: [x for x in r if x in frequent_singletons_list])\n",
    "      .filter(lambda r: len(r)>=2)\n",
    "      .flatMap(lambda r: list(combinations(r, 2)))\n",
    "      .map(lambda r:tuple(sorted(r)))\n",
    "      .map(lambda r:(r,1))\n",
    "      .reduceByKey(lambda a,b:a+b)\n",
    "      .collect()\n",
    ")\n",
    "pairs_counts[0:10]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('0553289713', 'B000HKLROQ'), 23),\n",
       " (('B0002XH6T8', 'B000HKLROQ'), 36),\n",
       " (('B00005WNTY', 'B000TKO3EA'), 35),\n",
       " (('B00005WNTY', 'B0007C10MS'), 24),\n",
       " (('B00005WNTY', 'B000I3NFKG'), 28),\n",
       " (('B00005WNTY', 'B0000CO4JZ'), 24),\n",
       " (('B000GQG5MA', 'B000I3NFKG'), 29),\n",
       " (('0553289713', 'B000NDSX6C'), 10),\n",
       " (('B000N76ZCC', 'B000NDSX6C'), 53),\n",
       " (('B000NDSX6C', 'B000Q032UY'), 3511)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "f9f477dc3a76b4dc",
   "metadata": {},
   "source": "We will filter the frequent pairs comparing them to a support threshold:"
  },
  {
   "cell_type": "code",
   "id": "ff54ec256a61402a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:25.959747Z",
     "start_time": "2025-03-31T13:29:25.957469Z"
    }
   },
   "source": [
    "frequent_pairs = list(filter(lambda r: r[1] >= support_threshold, pairs_counts))\n",
    "frequent_pairs\n",
    "print(\"There is a total of\", len(frequent_pairs), \"frequent pairs\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THere is a total of 84 frequent pairs\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "683e89e907b2360a",
   "metadata": {},
   "source": [
    "Most frequent pairs of books:"
   ]
  },
  {
   "cell_type": "code",
   "id": "82b5e2ff776c75d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:38:26.888924Z",
     "start_time": "2025-03-31T13:38:26.881644Z"
    }
   },
   "source": "sorted(frequent_pairs, key=lambda x: x[1], reverse=True)[0:10]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('B000ILIJE0', 'B000NDSX6C'), 3574),\n",
       " (('B000NDSX6C', 'B000NWU3I4'), 3562),\n",
       " (('B000ILIJE0', 'B000NWU3I4'), 3561),\n",
       " (('B000NDSX6C', 'B000Q032UY'), 3511),\n",
       " (('B000ILIJE0', 'B000Q032UY'), 3511),\n",
       " (('B000NWU3I4', 'B000Q032UY'), 3505),\n",
       " (('B000GQG5MA', 'B000NDSX6C'), 3408),\n",
       " (('B000GQG5MA', 'B000ILIJE0'), 3407),\n",
       " (('B000GQG5MA', 'B000NWU3I4'), 3402),\n",
       " (('B000GQG5MA', 'B000Q032UY'), 3354)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Third pass: finding frequent triplets",
   "id": "a2b7a0b4efaf0a4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:39:29.773017Z",
     "start_time": "2025-03-31T13:39:28.349671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "triplets_counts = (\n",
    "      book_baskets\n",
    "      .map(lambda r:r[1])\n",
    "      .map(lambda r: [x for x in r if x in frequent_singletons_list])\n",
    "      .filter(lambda r: len(r)>=2)\n",
    "      .flatMap(lambda r: list(combinations(r, 3)))\n",
    "      .map(lambda r:tuple(sorted(r)))\n",
    "      .map(lambda r:(r,1))\n",
    "      .reduceByKey(lambda a,b:a+b)\n",
    "      .collect()\n",
    ")\n",
    "triplets_counts[0:5]"
   ],
   "id": "3d4d2095304358bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('0553289713', 'B000PMCF1A', 'B000Q6XPDW'), 5),\n",
       " (('0553289713', 'B0007C10MS', 'B000PMCF1A'), 18),\n",
       " (('0553289713', 'B000I3NFKG', 'B000PMCF1A'), 55),\n",
       " (('0553289713', 'B0000CO4JZ', 'B000PMCF1A'), 18),\n",
       " (('0553289713', 'B0002XH6T8', 'B000Q6XPDW'), 7)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:27.115861Z",
     "start_time": "2025-03-31T13:29:27.111074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frequent_triplets = list(filter(lambda r: r[1] >= support_threshold, triplets_counts))\n",
    "frequent_triplets\n",
    "print(\"There is a total of\", len(frequent_triplets), \"frequent triplets\")"
   ],
   "id": "c310bb722bfaf3dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THere is a total of 111 frequent triplets\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:27.139154Z",
     "start_time": "2025-03-31T13:29:27.134014Z"
    }
   },
   "cell_type": "code",
   "source": "sorted(frequent_triplets, key=lambda x: x[1], reverse=True)[0:10]",
   "id": "3bc5ab61c3592b5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('B000ILIJE0', 'B000NDSX6C', 'B000NWU3I4'), 3561),\n",
       " (('B000ILIJE0', 'B000NDSX6C', 'B000Q032UY'), 3511),\n",
       " (('B000ILIJE0', 'B000NWU3I4', 'B000Q032UY'), 3505),\n",
       " (('B000NDSX6C', 'B000NWU3I4', 'B000Q032UY'), 3505),\n",
       " (('B000GQG5MA', 'B000ILIJE0', 'B000NDSX6C'), 3407),\n",
       " (('B000GQG5MA', 'B000NDSX6C', 'B000NWU3I4'), 3402),\n",
       " (('B000GQG5MA', 'B000ILIJE0', 'B000NWU3I4'), 3401),\n",
       " (('B000GQG5MA', 'B000NDSX6C', 'B000Q032UY'), 3354),\n",
       " (('B000GQG5MA', 'B000ILIJE0', 'B000Q032UY'), 3354),\n",
       " (('B000GQG5MA', 'B000NWU3I4', 'B000Q032UY'), 3348),\n",
       " (('B000BI4160', 'B000FAIRN2', 'B000J1OR0Y'), 1857),\n",
       " (('B000FAIRN2', 'B000GQK706', 'B000J1OR0Y'), 1851),\n",
       " (('B000FAIRN2', 'B000J1OR0Y', 'B000PIIMPW'), 1850),\n",
       " (('B000BI4160', 'B000FAIRN2', 'B000GQK706'), 1850),\n",
       " (('B000BI4160', 'B000GQK706', 'B000J1OR0Y'), 1850),\n",
       " (('B000BI4160', 'B000FAIRN2', 'B000PIIMPW'), 1849),\n",
       " (('B000BI4160', 'B000J1OR0Y', 'B000PIIMPW'), 1849),\n",
       " (('B000FAIRN2', 'B000H7EO2G', 'B000J1OR0Y'), 1848),\n",
       " (('B000BI4160', 'B000H7EO2G', 'B000J1OR0Y'), 1847),\n",
       " (('B000H7EO2G', 'B000J1OR0Y', 'B000PIIMPW'), 1847),\n",
       " (('B000FAIRN2', 'B000H7EO2G', 'B000PIIMPW'), 1847),\n",
       " (('B000BI4160', 'B000FAIRN2', 'B000H7EO2G'), 1847),\n",
       " (('B000BI4160', 'B000H7EO2G', 'B000PIIMPW'), 1846),\n",
       " (('B000GQK706', 'B000J1OR0Y', 'B000PIIMPW'), 1843),\n",
       " (('B000FAIRN2', 'B000GQK706', 'B000PIIMPW'), 1843),\n",
       " (('B000BI4160', 'B000GQK706', 'B000PIIMPW'), 1842),\n",
       " (('B000GQK706', 'B000H7EO2G', 'B000J1OR0Y'), 1841),\n",
       " (('B000FAIRN2', 'B000GQK706', 'B000H7EO2G'), 1841),\n",
       " (('B000GQK706', 'B000H7EO2G', 'B000PIIMPW'), 1840),\n",
       " (('B000BI4160', 'B000GQK706', 'B000H7EO2G'), 1840),\n",
       " (('B000I1VJLA', 'B000J1OR0Y', 'B000PIIMPW'), 1834),\n",
       " (('B000FAIRN2', 'B000I1VJLA', 'B000J1OR0Y'), 1834),\n",
       " (('B000FAIRN2', 'B000I1VJLA', 'B000PIIMPW'), 1834),\n",
       " (('B000BI4160', 'B000I1VJLA', 'B000J1OR0Y'), 1833),\n",
       " (('B000BI4160', 'B000FAIRN2', 'B000I1VJLA'), 1833),\n",
       " (('B000BI4160', 'B000I1VJLA', 'B000PIIMPW'), 1833),\n",
       " (('B000H7EO2G', 'B000I1VJLA', 'B000J1OR0Y'), 1831),\n",
       " (('B000FAIRN2', 'B000H7EO2G', 'B000I1VJLA'), 1831),\n",
       " (('B000H7EO2G', 'B000I1VJLA', 'B000PIIMPW'), 1831),\n",
       " (('B000BI4160', 'B000H7EO2G', 'B000I1VJLA'), 1830),\n",
       " (('B000FAIRN2', 'B000GQK706', 'B000I1VJLA'), 1827),\n",
       " (('B000GQK706', 'B000I1VJLA', 'B000J1OR0Y'), 1827),\n",
       " (('B000GQK706', 'B000I1VJLA', 'B000PIIMPW'), 1827),\n",
       " (('B000BI4160', 'B000GQK706', 'B000I1VJLA'), 1826),\n",
       " (('B000GQK706', 'B000H7EO2G', 'B000I1VJLA'), 1824),\n",
       " (('0141804459', '0435126075', '1844560333'), 1756),\n",
       " (('0141804459', '1844560333', '8188280046'), 1754),\n",
       " (('0435126075', '1844560333', '8188280046'), 1754),\n",
       " (('0141804459', '0435126075', '8188280046'), 1754),\n",
       " (('0808510258', 'B000JJVHZE', 'B000NNOTXI'), 1605),\n",
       " (('9562910334', 'B000GROP62', 'B000NHNM3C'), 1425),\n",
       " (('0460872702', 'B0000CO4JZ', 'B0007C10MS'), 1404),\n",
       " (('0460872702', 'B0007C10MS', 'B000EANQJ8'), 1389),\n",
       " (('0460872702', 'B0000CO4JZ', 'B000EANQJ8'), 1389),\n",
       " (('B0000CO4JZ', 'B0007C10MS', 'B000EANQJ8'), 1389),\n",
       " (('0451518845', '0460112872', '1847022251'), 1158),\n",
       " (('0140351310', '0451518845', '0460112872'), 1158),\n",
       " (('0435126024', '0582528259', '1587263971'), 1158),\n",
       " (('0140860428', '0582528259', '1847022251'), 1158),\n",
       " (('0140351310', '0140860428', '0582528259'), 1158),\n",
       " (('0140860428', '0435126024', '0451518845'), 1158),\n",
       " (('0435126024', '0451518845', '0460112872'), 1158),\n",
       " (('0140351310', '0140860428', '1587263971'), 1158),\n",
       " (('0435126024', '1587263971', '1847022251'), 1158),\n",
       " (('0140351310', '0582528259', '1587263971'), 1158),\n",
       " (('0140860428', '0435126024', '0460112872'), 1158),\n",
       " (('0140351310', '0435126024', '1847022251'), 1158),\n",
       " (('0140860428', '0451518845', '1587263971'), 1158),\n",
       " (('0451518845', '0582528259', '1587263971'), 1158),\n",
       " (('0435126024', '0451518845', '1847022251'), 1158),\n",
       " (('0140351310', '0435126024', '0451518845'), 1158),\n",
       " (('0140860428', '0460112872', '1587263971'), 1158),\n",
       " (('0460112872', '0582528259', '1587263971'), 1158),\n",
       " (('0140860428', '0435126024', '1847022251'), 1158),\n",
       " (('0435126024', '0460112872', '1847022251'), 1158),\n",
       " (('0140351310', '0435126024', '0460112872'), 1158),\n",
       " (('0451518845', '1587263971', '1847022251'), 1158),\n",
       " (('0140860428', '0451518845', '0460112872'), 1158),\n",
       " (('0451518845', '0460112872', '0582528259'), 1158),\n",
       " (('0460112872', '1587263971', '1847022251'), 1158),\n",
       " (('0140351310', '0435126024', '1587263971'), 1158),\n",
       " (('0140351310', '0140860428', '1847022251'), 1158),\n",
       " (('0140351310', '0582528259', '1847022251'), 1158),\n",
       " (('0435126024', '0451518845', '1587263971'), 1158),\n",
       " (('0140860428', '0451518845', '1847022251'), 1158),\n",
       " (('0140351310', '0140860428', '0451518845'), 1158),\n",
       " (('0451518845', '0582528259', '1847022251'), 1158),\n",
       " (('0140351310', '0451518845', '0582528259'), 1158),\n",
       " (('0140860428', '0435126024', '1587263971'), 1158),\n",
       " (('0140351310', '1587263971', '1847022251'), 1158),\n",
       " (('0435126024', '0460112872', '1587263971'), 1158),\n",
       " (('0140860428', '0460112872', '1847022251'), 1158),\n",
       " (('0140351310', '0140860428', '0460112872'), 1158),\n",
       " (('0460112872', '0582528259', '1847022251'), 1158),\n",
       " (('0140351310', '0460112872', '0582528259'), 1158),\n",
       " (('0140351310', '0451518845', '1587263971'), 1158),\n",
       " (('0435126024', '0451518845', '0582528259'), 1158),\n",
       " (('0140351310', '0460112872', '1587263971'), 1158),\n",
       " (('0140860428', '0435126024', '0582528259'), 1158),\n",
       " (('0435126024', '0460112872', '0582528259'), 1158),\n",
       " (('0451518845', '0460112872', '1587263971'), 1158),\n",
       " (('0140860428', '0582528259', '1587263971'), 1158),\n",
       " (('0140351310', '0140860428', '0435126024'), 1158),\n",
       " (('0435126024', '0582528259', '1847022251'), 1158),\n",
       " (('0140351310', '0435126024', '0582528259'), 1158),\n",
       " (('0140860428', '0451518845', '0582528259'), 1158),\n",
       " (('0140351310', '0451518845', '1847022251'), 1158),\n",
       " (('0140860428', '1587263971', '1847022251'), 1158),\n",
       " (('0582528259', '1587263971', '1847022251'), 1158),\n",
       " (('0140860428', '0460112872', '0582528259'), 1158),\n",
       " (('0140351310', '0460112872', '1847022251'), 1158)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "de69a2420ae7105c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. SON Algorithm\n",
    "\n",
    "The **SON (Savasere, Omiecinski, and Navathe) Algorithm** is a scalable approach for **frequent itemset mining in large-scale datasets**, particularly suited for distributed computing environments. Unlike the standard **A-Priori Algorithm**, which scans the entire dataset multiple times, SON leverages a **divide-and-conquer strategy** by breaking the dataset into **independent chunks** that are processed in parallel.\n",
    "\n",
    "This method allows **local frequent itemsets** to be identified in each chunk before combining them to find **global frequent itemsets** across the entire dataset. By working on smaller partitions first, SON reduces memory consumption and improves efficiency in distributed systems.\n",
    "\n",
    "When implemented with **MapReduce**, the algorithm is executed in two **MapReduce passes**:\n",
    "\n",
    "1. **First Pass:** Identifies locally frequent itemsets within each chunk and merges them into a set of candidate itemsets.\n",
    "2. **Second Pass:** Computes the **global support** of the candidate itemsets across all data chunks and extracts the final **frequent itemsets**.\n",
    "\n",
    "This approach significantly improves **scalability** by distributing computation across multiple nodes, making it well-suited for handling massive datasets in a parallel computing environment."
   ]
  },
  {
   "cell_type": "code",
   "id": "1212783ffcf1fd43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:28.902463Z",
     "start_time": "2025-03-31T13:29:27.157730Z"
    }
   },
   "source": [
    "# conversion of baskets from rdd to list\n",
    "SON_baskets = book_baskets.collect()\n",
    "SON_baskets = [basket for _, basket in SON_baskets]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "3a608e7aa75c03da",
   "metadata": {},
   "source": [
    "At first, I **parallelised** the basket dataset in 10 partitions and set the **minimum support** (both local and global):"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd9d32e6be3c6ddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:29:29.166516Z",
     "start_time": "2025-03-31T13:29:28.913199Z"
    }
   },
   "source": [
    "# Parallelizing (10 partitions)\n",
    "rdd = spark.sparkContext.parallelize(SON_baskets, numSlices=10)\n",
    "\n",
    "# Set local and global support\n",
    "s = support_threshold  # Global support\n",
    "p = 1 / rdd.getNumPartitions()  # Fraction of data for each partition\n",
    "local_s = s * p  # Local support"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "53e0fbb8027324d8",
   "metadata": {},
   "source": "In the **first phase**, we want to find candidate frequent itemsets locally (chunk by chunk) and merge them in a set of global candidates:"
  },
  {
   "cell_type": "code",
   "id": "2cacb0d6a392b81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:06.400958Z",
     "start_time": "2025-03-31T13:29:29.174634Z"
    }
   },
   "source": [
    "### FIRST PHASE MAPREDUCE: FIND-LOCAL FREQUENT ITEMSETS ###\n",
    "\n",
    "def find_frequent_itemsets(partition):\n",
    "    partition_list = list(partition)  # conversion to list for iteration\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    # creating itemsets\n",
    "    for basket in partition_list:\n",
    "        for item in basket:\n",
    "            counts[frozenset([item])] += 1  # Single itemsets\n",
    "        for pair in combinations(basket, 2):  # 2 element itemsets\n",
    "            counts[frozenset(pair)] += 1\n",
    "\n",
    "    # Find locally frequent itemsets\n",
    "    frequent_itemsets = [itemset for itemset, count in counts.items() if count >= local_s]\n",
    "\n",
    "    return [(itemset, 1) for itemset in frequent_itemsets]\n",
    "\n",
    "# MAP 1: Find local candidates\n",
    "candidates_rdd = rdd.mapPartitions(find_frequent_itemsets)\n",
    "\n",
    "# REDUCE 1: Merge local candidates to get global candidates\n",
    "candidates = candidates_rdd.distinct().collect()\n",
    "candidates_set = set(candidates)  # Conversion to set\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 15:29:29 WARN TaskSetManager: Stage 100 contains a task of very large size (3267 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "373bae6a8bb65b15",
   "metadata": {},
   "source": [
    "In the second phase, I will compare the frequent itemsets on all partitions and compare them with the global support:"
   ]
  },
  {
   "cell_type": "code",
   "id": "26f9806eacf56f2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:16.913712Z",
     "start_time": "2025-03-31T13:31:06.474552Z"
    }
   },
   "source": [
    "### SECOND PHASE MAPREDUCE: COMPUTE GLOBAL SUPPORT ###\n",
    "\n",
    "def count_candidates(partition):\n",
    "    partition_list = list(partition)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for basket in partition_list:\n",
    "        for candidate in candidates_set:\n",
    "            if candidate[0].issubset(set(basket)):  # is candidate in the basket?\n",
    "                counts[candidate[0]] += 1\n",
    "\n",
    "    return counts.items()\n",
    "\n",
    "# MAP 2: Count frequency of candidate itemsets in dataset chunks\n",
    "counts_rdd = rdd.mapPartitions(count_candidates)\n",
    "\n",
    "# REDUCE 2: Get counts and filter globally frequent itemsets\n",
    "frequent_itemsets = counts_rdd.reduceByKey(lambda x, y: x + y) \\\n",
    "                             .filter(lambda x: x[1] >= s) \\\n",
    "                             .collect()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 15:31:06 WARN TaskSetManager: Stage 102 contains a task of very large size (3267 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "bec8440ad3ad85cd",
   "metadata": {},
   "source": [
    "Below **results**, ordered in descending order of support:\n",
    "\n",
    "**Generally frequent itemsets**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa2fd898d82ae1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:44:20.729547Z",
     "start_time": "2025-03-31T13:44:20.724065Z"
    }
   },
   "source": "sorted(frequent_itemsets, key=lambda x: x[1], reverse=True)[0:10]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'B000IEZE3G'}), 3663),\n",
       " (frozenset({'B000NDSX6C'}), 3577),\n",
       " (frozenset({'B000ILIJE0'}), 3576),\n",
       " (frozenset({'B000ILIJE0', 'B000NDSX6C'}), 3574),\n",
       " (frozenset({'B000NWU3I4'}), 3562),\n",
       " (frozenset({'B000NDSX6C', 'B000NWU3I4'}), 3562),\n",
       " (frozenset({'B000ILIJE0', 'B000NWU3I4'}), 3561),\n",
       " (frozenset({'B000NDSX6C', 'B000Q032UY'}), 3511),\n",
       " (frozenset({'B000ILIJE0', 'B000Q032UY'}), 3511),\n",
       " (frozenset({'B000Q032UY'}), 3511)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "e2fd9de71d60179a",
   "metadata": {},
   "source": [
    "**2-element frequent itemsets**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c00fd9f15c76101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:44:34.479437Z",
     "start_time": "2025-03-31T13:44:34.473914Z"
    }
   },
   "source": [
    "filtered_itemsets = [itemset for itemset in frequent_itemsets if len(itemset[0]) == 2]\n",
    "sorted(filtered_itemsets, key=lambda x: x[1], reverse=True)[0:10]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'B000ILIJE0', 'B000NDSX6C'}), 3574),\n",
       " (frozenset({'B000NDSX6C', 'B000NWU3I4'}), 3562),\n",
       " (frozenset({'B000ILIJE0', 'B000NWU3I4'}), 3561),\n",
       " (frozenset({'B000NDSX6C', 'B000Q032UY'}), 3511),\n",
       " (frozenset({'B000ILIJE0', 'B000Q032UY'}), 3511),\n",
       " (frozenset({'B000NWU3I4', 'B000Q032UY'}), 3505),\n",
       " (frozenset({'B000GQG5MA', 'B000NDSX6C'}), 3408),\n",
       " (frozenset({'B000GQG5MA', 'B000ILIJE0'}), 3407),\n",
       " (frozenset({'B000GQG5MA', 'B000NWU3I4'}), 3402),\n",
       " (frozenset({'B000GQG5MA', 'B000Q032UY'}), 3354)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "id": "d90e2d3fa69e0983",
   "metadata": {},
   "source": [
    "---\n",
    "## Association rules\n",
    "\n",
    "Association rules are used to uncover relationships between items in large transactional datasets. They are fundamental in market-basket analysis, helping to identify patterns in purchasing behavior. Given a set of frequent itemsets, association rules allow us to infer how the presence of one item (or a set of items) influences the likelihood of another item appearing in the same transaction.\n",
    "\n",
    "The key metrics used to evaluate association rules are:\n",
    "\n",
    "* **Support**: Measures how frequently an itemset appears in the dataset.\n",
    "$$\n",
    "Support(A) = \\frac{\\text{Count}(A)}{\\text{Total Transactions}}\n",
    "$$\n",
    "* **Confidence**: Represents the probability that an item B is purchased given that item A is also purchased.\n",
    "$$\n",
    "Confidence(A \\Rightarrow B) = \\frac{Support(A \\cup B)}{Support(A)}\n",
    "$$\n",
    "* **Lift**: Indicates how much more likely item B is to appear with item A compared to if they were independent.\n",
    "$$\n",
    "Lift(A \\Rightarrow B) = \\frac{Confidence(A \\Rightarrow B)}{Support(B)}\n",
    "$$\n",
    "\n",
    "By analyzing these metrics, we can determine which itemsets provide the most meaningful associations and can be used for applications such as recommendation systems and targeted marketing.\n",
    "\n",
    "---\n",
    "\n",
    "#### Association rules from pairs\n",
    "\n",
    "At first, we created two dataframes to store frequent singletons and pairs, and computed their support:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8f779a5391952808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:17.026755Z",
     "start_time": "2025-03-31T13:31:16.987801Z"
    }
   },
   "source": [
    "# Compute total number of baskets (avoid collect() for performance)\n",
    "total_baskets = number_of_baskets\n",
    "\n",
    "# Dataframe for frequent singletons and compute support\n",
    "df_singles = pd.DataFrame(frequent_singletons, columns=['Item', 'Count'])\n",
    "df_singles['Support'] = df_singles['Count'] / total_baskets\n",
    "df_singles"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Item  Count   Support\n",
       "0   0553289713   1578  0.001565\n",
       "1   B000PMCF1A   2125  0.002107\n",
       "2   B0002XH6T8   1408  0.001396\n",
       "3   B000K0DB8I   1469  0.001457\n",
       "4   B000NWU3I4   3562  0.003532\n",
       "..         ...    ...       ...\n",
       "76  B000TZ19TC   1146  0.001136\n",
       "77  1587263971   1165  0.001155\n",
       "78  B000FAIRN2   1859  0.001843\n",
       "79  B000GQK706   1852  0.001837\n",
       "80  1586216147   1060  0.001051\n",
       "\n",
       "[81 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Count</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0553289713</td>\n",
       "      <td>1578</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000PMCF1A</td>\n",
       "      <td>2125</td>\n",
       "      <td>0.002107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0002XH6T8</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000K0DB8I</td>\n",
       "      <td>1469</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000NWU3I4</td>\n",
       "      <td>3562</td>\n",
       "      <td>0.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B000TZ19TC</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1587263971</td>\n",
       "      <td>1165</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>B000FAIRN2</td>\n",
       "      <td>1859</td>\n",
       "      <td>0.001843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>B000GQK706</td>\n",
       "      <td>1852</td>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1586216147</td>\n",
       "      <td>1060</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "fde2b94755d5ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:17.057746Z",
     "start_time": "2025-03-31T13:31:17.045943Z"
    }
   },
   "source": [
    "# Dataframe for frequent pairs and compute support\n",
    "df_pairs = pd.DataFrame(frequent_pairs, columns=['Pair', 'Count'])\n",
    "df_pairs['Support'] = df_pairs['Count'] / total_baskets\n",
    "df_pairs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Pair  Count   Support\n",
       "0   (B000NDSX6C, B000Q032UY)   3511  0.003482\n",
       "1   (0435126024, 0451518845)   1158  0.001148\n",
       "2   (0140860428, 0435126024)   1158  0.001148\n",
       "3   (0435126024, 0460112872)   1158  0.001148\n",
       "4   (B0006Y8M7S, B00086Q244)   1034  0.001025\n",
       "..                       ...    ...       ...\n",
       "79  (0140351310, 0460112872)   1158  0.001148\n",
       "80  (B000BI4160, B000I1VJLA)   1833  0.001818\n",
       "81  (B000FAIRN2, B000H7EO2G)   1848  0.001833\n",
       "82  (B000GQK706, B000H7EO2G)   1841  0.001826\n",
       "83  (B000JJVHZE, B000NNOTXI)   1617  0.001603\n",
       "\n",
       "[84 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>Count</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(B000NDSX6C, B000Q032UY)</td>\n",
       "      <td>3511</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0435126024, 0451518845)</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0140860428, 0435126024)</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0435126024, 0460112872)</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(B0006Y8M7S, B00086Q244)</td>\n",
       "      <td>1034</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>(0140351310, 0460112872)</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>(B000BI4160, B000I1VJLA)</td>\n",
       "      <td>1833</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>(B000FAIRN2, B000H7EO2G)</td>\n",
       "      <td>1848</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(B000GQK706, B000H7EO2G)</td>\n",
       "      <td>1841</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>(B000JJVHZE, B000NNOTXI)</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "6f6e8c1b99ca920a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:17.353777Z",
     "start_time": "2025-03-31T13:31:17.346291Z"
    }
   },
   "source": [
    "# Split elements in pairs\n",
    "df_pairs[['Item_A', 'Item_B']] = pd.DataFrame(df_pairs['Pair'].tolist(), index=df_pairs.index)\n",
    "df_pairs.drop(columns=['Pair'], inplace=True)\n",
    "df_pairs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Count   Support      Item_A      Item_B\n",
       "0    3511  0.003482  B000NDSX6C  B000Q032UY\n",
       "1    1158  0.001148  0435126024  0451518845\n",
       "2    1158  0.001148  0140860428  0435126024\n",
       "3    1158  0.001148  0435126024  0460112872\n",
       "4    1034  0.001025  B0006Y8M7S  B00086Q244\n",
       "..    ...       ...         ...         ...\n",
       "79   1158  0.001148  0140351310  0460112872\n",
       "80   1833  0.001818  B000BI4160  B000I1VJLA\n",
       "81   1848  0.001833  B000FAIRN2  B000H7EO2G\n",
       "82   1841  0.001826  B000GQK706  B000H7EO2G\n",
       "83   1617  0.001603  B000JJVHZE  B000NNOTXI\n",
       "\n",
       "[84 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Support</th>\n",
       "      <th>Item_A</th>\n",
       "      <th>Item_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3511</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>B000NDSX6C</td>\n",
       "      <td>B000Q032UY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0435126024</td>\n",
       "      <td>0451518845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0140860428</td>\n",
       "      <td>0435126024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0435126024</td>\n",
       "      <td>0460112872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1034</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>B0006Y8M7S</td>\n",
       "      <td>B00086Q244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0140351310</td>\n",
       "      <td>0460112872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1833</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>B000BI4160</td>\n",
       "      <td>B000I1VJLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1848</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>B000FAIRN2</td>\n",
       "      <td>B000H7EO2G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1841</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>B000GQK706</td>\n",
       "      <td>B000H7EO2G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1617</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>B000JJVHZE</td>\n",
       "      <td>B000NNOTXI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, I merged singles and pairs to get the support of each pair and compute confidence and lift:",
   "id": "3ef3f551d31f52b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:17.393319Z",
     "start_time": "2025-03-31T13:31:17.384032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_pairs = df_pairs.merge(\n",
    "    df_singles[['Item', 'Count', 'Support']],\n",
    "    how='left',\n",
    "    left_on='Item_A',\n",
    "    right_on='Item'\n",
    ").rename(columns={\n",
    "    'Count': 'Count_A',\n",
    "    'Support': 'Support_A',\n",
    "    'Item': 'Item_A_singles'\n",
    "})\n",
    "\n",
    "df_pairs = df_pairs.merge(\n",
    "    df_singles[['Item', 'Count', 'Support']],\n",
    "    how='left',\n",
    "    left_on='Item_B',\n",
    "    right_on='Item'\n",
    ").rename(columns={\n",
    "    'Count': 'Count_B',\n",
    "    'Support': 'Support_B',\n",
    "    'Item': 'Item_B_singles'\n",
    "})\n",
    "\n",
    "df_pairs.drop(columns=['Item_A_singles', 'Item_B_singles'], inplace=True)\n",
    "df_pairs.rename(columns={'Count_x': 'Count_AB', 'Support_x': 'Support_AB', 'Support_y': 'Support_A', 'Count_y': 'Count_A'}, inplace=True)"
   ],
   "id": "d6a1182a1fcf151d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "f7b233052e4211fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:17.551396Z",
     "start_time": "2025-03-31T13:31:17.544150Z"
    }
   },
   "source": [
    "df_pairs['Confidence A→B'] = df_pairs['Support_AB'] / df_pairs['Support_A']\n",
    "df_pairs['Confidence B→A'] = df_pairs['Support_AB'] / df_pairs['Support_B']\n",
    "df_pairs['Lift'] = df_pairs['Confidence A→B'] / (df_pairs['Support_B'])\n",
    "\n",
    "df_pairs.sort_values(by='Lift', ascending=False)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Count_AB  Support_AB      Item_A      Item_B  Count_A  Support_A  Count_B  \\\n",
       "10      1010    0.001002  B000HKLROQ  B000TKO3EA     1010   0.001002     1010   \n",
       "4       1034    0.001025  B0006Y8M7S  B00086Q244     1036   0.001027     1040   \n",
       "35      1146    0.001136  0003300277  B000TZ19TC     1147   0.001137     1146   \n",
       "1       1158    0.001148  0435126024  0451518845     1158   0.001148     1158   \n",
       "40      1158    0.001148  0140351310  0582528259     1158   0.001148     1158   \n",
       "..       ...         ...         ...         ...      ...        ...      ...   \n",
       "45      3562    0.003532  B000NDSX6C  B000NWU3I4     3577   0.003547     3562   \n",
       "0       3511    0.003482  B000NDSX6C  B000Q032UY     3577   0.003547     3511   \n",
       "65      3561    0.003531  B000ILIJE0  B000NWU3I4     3576   0.003546     3562   \n",
       "13      3407    0.003379  B000GQG5MA  B000ILIJE0     3408   0.003380     3576   \n",
       "44      3574    0.003544  B000ILIJE0  B000NDSX6C     3576   0.003546     3577   \n",
       "\n",
       "    Support_B  Confidence A→B  Confidence B→A        Lift  \n",
       "10   0.001002        1.000000        1.000000  998.438614  \n",
       "4    0.001031        0.998069        0.994231  967.765613  \n",
       "35   0.001136        0.999128        1.000000  879.183086  \n",
       "1    0.001148        1.000000        1.000000  870.831606  \n",
       "40   0.001148        1.000000        1.000000  870.831606  \n",
       "..        ...             ...             ...         ...  \n",
       "45   0.003532        0.995807        1.000000  281.918647  \n",
       "0    0.003482        0.981549        1.000000  281.918647  \n",
       "65   0.003532        0.995805        0.999719  281.918315  \n",
       "13   0.003546        0.999707        0.952740  281.914737  \n",
       "44   0.003547        0.999441        0.999161  281.760974  \n",
       "\n",
       "[84 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_AB</th>\n",
       "      <th>Support_AB</th>\n",
       "      <th>Item_A</th>\n",
       "      <th>Item_B</th>\n",
       "      <th>Count_A</th>\n",
       "      <th>Support_A</th>\n",
       "      <th>Count_B</th>\n",
       "      <th>Support_B</th>\n",
       "      <th>Confidence A→B</th>\n",
       "      <th>Confidence B→A</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1010</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>B000HKLROQ</td>\n",
       "      <td>B000TKO3EA</td>\n",
       "      <td>1010</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1010</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>998.438614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1034</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>B0006Y8M7S</td>\n",
       "      <td>B00086Q244</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.994231</td>\n",
       "      <td>967.765613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1146</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0003300277</td>\n",
       "      <td>B000TZ19TC</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>879.183086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0435126024</td>\n",
       "      <td>0451518845</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>870.831606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0140351310</td>\n",
       "      <td>0582528259</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>1158</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>870.831606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3562</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>B000NDSX6C</td>\n",
       "      <td>B000NWU3I4</td>\n",
       "      <td>3577</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>3562</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>281.918647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3511</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>B000NDSX6C</td>\n",
       "      <td>B000Q032UY</td>\n",
       "      <td>3577</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>3511</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.981549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>281.918647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3561</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>B000ILIJE0</td>\n",
       "      <td>B000NWU3I4</td>\n",
       "      <td>3576</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>3562</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>0.999719</td>\n",
       "      <td>281.918315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3407</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>B000GQG5MA</td>\n",
       "      <td>B000ILIJE0</td>\n",
       "      <td>3408</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>3576</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.952740</td>\n",
       "      <td>281.914737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3574</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>B000ILIJE0</td>\n",
       "      <td>B000NDSX6C</td>\n",
       "      <td>3576</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>3577</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.999441</td>\n",
       "      <td>0.999161</td>\n",
       "      <td>281.760974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's take, for example, the first association rule:\n",
    "- A **confidence A→B** of 1.0 indicates that whenever item A appears in a basket, item B also appears.\n",
    "- The **confidence B→A** of 1.0 suggests that B almost always co-occurs with A, but not perfectly.\n",
    "- An extremely high **lift** (e.g., ~998), in this case, represents the main issue in this dataset: even if we tried to remove ID with same title, there are still some duplicates left due to typing mistakes or different editions of the same book."
   ],
   "id": "e83437629cba1f08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The following code block simply queries the dataset to find the titles of the books related to a specific association rule:"
   ],
   "id": "59cde763bc3b069c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:27.097933Z",
     "start_time": "2025-03-31T13:31:17.781664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"SELECT DISTINCT Id, Title FROM Ratings WHERE ID = 'B000HKLROQ' OR ID = 'B000TKO3EA'\"\n",
    "most_connected = spark.sql(query)\n",
    "most_connected.show()"
   ],
   "id": "16d1965020ac8a51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|        Id|               Title|\n",
      "+----------+--------------------+\n",
      "|B000TKO3EA|middlesex [unabri...|\n",
      "|B000HKLROQ|           middlesex|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:35.268808Z",
     "start_time": "2025-03-31T13:31:27.133680Z"
    }
   },
   "cell_type": "code",
   "source": "most_connectid = most_connected.collect()",
   "id": "19138d7719eba9e1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/03/31 15:31:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:31:35.298117Z",
     "start_time": "2025-03-31T13:31:35.295077Z"
    }
   },
   "cell_type": "code",
   "source": "most_connectid",
   "id": "779646ac52c50479",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='B000TKO3EA', Title='middlesex [unabridged audiobook]'),\n",
       " Row(Id='B000HKLROQ', Title='middlesex')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
